{"componentChunkName":"component---src-templates-lesson-template-js","path":"/cgroups","webpackCompilationHash":"81c643f50e8a99285311","result":{"data":{"markdownRemark":{"html":"<p>Okay, so now we've hidden the processes from Eve so Bob and Alice can engage in commerce in privacy and peace. So we're all good, right? They can no longer mess each other, right? Not quite. We're almost there.</p>\n<p>So now say it's Black Friday, Boxing Day or Singles' Day (three of the biggest shopping days in the year, pick the one that makes the most sense to you ðŸ˜„) and Bob and Alice are gearing up for their biggest sales day of the year. Everything is ready to go and at 9:00AM their site suddenly goes down without warning. What happened!? They log on to their chroot'd, unshare'd shell on your server and see that the CPU is pegged at 100% and there's no more memory available to allocate! Oh no! What happened?</p>\n<p>The first explanation could be that Eve has her site running on another server and simple logged on and ran a program that ate up all the available resources so that Bob and Alice so that their sites would go down and Eve would be the only site that was up, increasing her sales.</p>\n<p>However another, possibly more likely explanation is that both Bob's and Alice's sites got busy at the same time and that in-and-of-itself took all the resources without any malice involved, taking down their sites and everyone else on the server. Or perhaps Bob's site had a memory leak and that was enough to take all the resources available.</p>\n<p>Suffice to say, we still have a problem. Every isolated environment has access to all <em>physical</em> resources of the server. There's no isolation of physical components from these environments.</p>\n<p>Enter the hero of this story: cgroups, or control groups. Google saw this same problem when building their own infrastructure and wanted to protect runaway processes from taking down entire servers and made this idea of cgroups so you can say \"this isolated environment only gets so much CPU, so much memory, etc. and once it's out of those it's out-of-luck, it won't get any more.\"</p>\n<p>This is a bit more difficult to accomplish but let's go ahead and give it a shot.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># outside of unshare'd environment get the tools we'll need here</span>\n<span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> -y cgroup-tools <span class=\"token function\">htop</span>\n\n<span class=\"token comment\"># create new cgroups</span>\ncgcreate -g cpu,memory,blkio,devices,freezer:/sandbox\n\n<span class=\"token comment\"># add our unshare'd env to our cgroup</span>\n<span class=\"token function\">ps</span> aux <span class=\"token comment\"># grab the bash PID that's right after the unshare one</span>\ncgclassify -g cpu,memory,blkio,devices,freezer:sandbox <span class=\"token operator\">&lt;</span>PID<span class=\"token operator\">></span>\n\n<span class=\"token comment\"># list tasks associated to the sandbox cpu group, we should see the above PID</span>\n<span class=\"token function\">cat</span> /sys/fs/cgroup/cpu/sandbox/tasks\n\n<span class=\"token comment\"># show the cpu share of the sandbox cpu group, this is the number that determines priority between competing resources, higher is is higher priority</span>\n<span class=\"token function\">cat</span> /sys/fs/cgroup/cpu/sandbox/cpu.shares\n\n<span class=\"token comment\"># kill all of sandbox's processes if you need it</span>\n<span class=\"token comment\"># kill -9 $(cat /sys/fs/cgroup/cpu/sandbox/tasks)</span>\n\n<span class=\"token comment\"># Limit usage at 5% for a multi core system</span>\ncgset -r cpu.cfs_period_us<span class=\"token operator\">=</span><span class=\"token number\">100000</span> -r cpu.cfs_quota_us<span class=\"token operator\">=</span>$<span class=\"token punctuation\">[</span> <span class=\"token number\">5000</span> * <span class=\"token variable\"><span class=\"token variable\">$(</span>getconf _NPROCESSORS_ONLN<span class=\"token variable\">)</span></span> <span class=\"token punctuation\">]</span> sandbox\n\n<span class=\"token comment\"># Set a limit of 80M</span>\ncgset -r memory.limit_in_bytes<span class=\"token operator\">=</span>80M sandbox\n<span class=\"token comment\"># Get memory stats used by the cgroup</span>\ncgget -r memory.stat sandbox\n\n<span class=\"token comment\"># in terminal session #2, outside of the unshare'd env</span>\n<span class=\"token function\">htop</span> <span class=\"token comment\"># will allow us to see resources being used with a nice visualizer</span>\n\n<span class=\"token comment\"># in terminal session #1, inside unshared'd env</span>\n<span class=\"token function\">yes</span> <span class=\"token operator\">></span> /dev/null <span class=\"token comment\"># this will instantly consume one core's worth of CPU power</span>\n<span class=\"token comment\"># notice it's only taking 5% of the CPU, like we set</span>\n<span class=\"token comment\"># if you want, run the docker exec from above to get a third session to see the above command take 100% of the available resources</span>\n<span class=\"token comment\"># CTRL+C stops the above any time</span>\n\n<span class=\"token comment\"># in terminal session #1, inside unshare'd env</span>\n<span class=\"token function\">yes</span> <span class=\"token operator\">|</span> <span class=\"token function\">tr</span> <span class=\"token punctuation\">\\</span><span class=\"token punctuation\">\\</span>n x <span class=\"token operator\">|</span> <span class=\"token function\">head</span> -c <span class=\"token number\">1048576000</span> <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> n <span class=\"token comment\"># this will ramp up to consume ~1GB of RAM</span>\n<span class=\"token comment\"># notice in htop it'll keep the memory closer to 80MB due to our cgroup</span>\n<span class=\"token comment\"># as above, connect with a third terminal to see it work outside of a cgroup</span></code></pre></div>\n<p>And now we can call this a container. Using these features together, we allow Bob, Alice, and Eve to run whatever code they want and the only people they can mess with is themselves.</p>\n<p>So while this is a container at its most basic sense, we haven't broached more advance topics like networking, deploying, bundling, or anything else that something like Docker takes care of for us. But now you know at its most base level what a container is, what it does, and how you <em>could</em> do this yourself but you'll be grateful that Docker does it for you. On to the next lesson!</p>","frontmatter":{"path":"/cgroups","title":"cgroups","order":2.3}},"allMarkdownRemark":{"edges":[{"node":{"frontmatter":{"order":1,"path":"/intro","title":"Introduction"}}},{"node":{"frontmatter":{"order":2,"path":"/what-are-containers","title":"What Are Containers?"}}},{"node":{"frontmatter":{"order":2.1,"path":"/chroot","title":"chroot"}}},{"node":{"frontmatter":{"order":2.2,"path":"/namespaces","title":"Namespaces"}}},{"node":{"frontmatter":{"order":2.3,"path":"/cgroups","title":"cgroups"}}},{"node":{"frontmatter":{"order":3,"path":"/getting-set-up-with-docker","title":"Getting Set Up with Docker"}}},{"node":{"frontmatter":{"order":3.1,"path":"/docker-images-without-docker","title":"Docker Images without Docker"}}},{"node":{"frontmatter":{"order":3.2,"path":"/docker-images-with-docker","title":"Docker Images with Docker"}}},{"node":{"frontmatter":{"order":3.3,"path":"/nodejs-on-docker","title":"Node.js on Docker"}}},{"node":{"frontmatter":{"order":3.5,"path":"/docker-cli","title":"Docker CLI"}}},{"node":{"frontmatter":{"order":3.5,"path":"/tags","title":"Tags"}}},{"node":{"frontmatter":{"order":4,"path":"/dockerfile","title":"Intro to Dockerfiles"}}},{"node":{"frontmatter":{"order":4.1,"path":"/build-a-nodejs-app","title":"Build a Node.js App"}}},{"node":{"frontmatter":{"order":4.2,"path":"/more-complicated-nodejs-app","title":"A More Complicated Node.js App"}}},{"node":{"frontmatter":{"order":4.4,"path":"/expose","title":"A Note on EXPOSE"}}},{"node":{"frontmatter":{"order":4.5,"path":"/layers","title":"Layers"}}},{"node":{"frontmatter":{"order":5,"path":"/alpine-linux","title":"Alpine Linux"}}},{"node":{"frontmatter":{"order":5.1,"path":"/making-our-own-alpine-nodejs-container","title":"Making Our Own Alpine Node.js Container"}}},{"node":{"frontmatter":{"order":5.2,"path":"/multi-stage-builds","title":"Multi Stage Builds"}}},{"node":{"frontmatter":{"order":5.3,"path":"/static-assets-project","title":"Static Assets Project"}}},{"node":{"frontmatter":{"order":6,"path":"/bind-mounts","title":"Bind Mounts"}}},{"node":{"frontmatter":{"order":6.1,"path":"/volumes","title":"Volumes"}}},{"node":{"frontmatter":{"order":6.2,"path":"/dev-containers","title":"Using Containers for your Dev Environment"}}},{"node":{"frontmatter":{"order":6.3,"path":"/visual-studio-code","title":"Dev Containers with Visual Studio Code"}}},{"node":{"frontmatter":{"order":6.4,"path":"/networking","title":"Networking with Docker"}}},{"node":{"frontmatter":{"order":7,"path":"/docker-compose","title":"Docker Compose"}}},{"node":{"frontmatter":{"order":7.1,"path":"/kubernetes","title":"Kubernetes"}}},{"node":{"frontmatter":{"order":7.2,"path":"/kompose","title":"Kompose"}}},{"node":{"frontmatter":{"order":8,"path":"/buildah","title":"Buildah"}}},{"node":{"frontmatter":{"order":8.1,"path":"/podman","title":"Podman"}}},{"node":{"frontmatter":{"order":13,"path":"/conclusion","title":"Conclusion"}}}]}},"pageContext":{"isCreatedByStatefulCreatePages":false}}}